{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_labels = pd.read_csv(\"E://table//PRS/all_labels.csv\")\n",
    "data_prs = pd.read_csv(\"E://table//PRS/all_prs.csv\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "class PRSDataset(Dataset):\n",
    "    def __init__(self, prs_data, labels):\n",
    "        self.prs_data = prs_data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prs_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.prs_data.iloc[idx].values, dtype=torch.float32)\n",
    "        y = torch.tensor(self.labels.iloc[idx].values, dtype=torch.float32)\n",
    "        return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Normalizing the PRS data\n",
    "scaler = StandardScaler()\n",
    "data_prs.iloc[:, 1:] = scaler.fit_transform(data_prs.iloc[:, 1:])  # Normalize PRS features (excluding ID column)\n",
    "\n",
    "# Merging labels and PRS datasets by ID\n",
    "merged_data = data_prs.merge(data_labels, left_on='FID', right_on='eid')\n",
    "prs_data = merged_data.iloc[:, 1:81]  # Extract PRS columns\n",
    "disease_labels = merged_data.iloc[:, 82:]  # Extract labels columns\n",
    "\n",
    "# Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(prs_data, disease_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoader\n",
    "dataset_train = PRSDataset(X_train, y_train)\n",
    "dataset_test = PRSDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=64, shuffle=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define Attention Mechanism\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attention_weights = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = self.attention_weights(x)\n",
    "        weights = torch.softmax(scores, dim=1)\n",
    "        context = torch.sum(weights * x, dim=1)\n",
    "        return context, weights\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define Multi-Task Model with Attention Mechanism\n",
    "class MultiTaskAttentionModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_tasks):\n",
    "        super(MultiTaskAttentionModel, self).__init__()\n",
    "        self.shared_encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.attention = Attention(hidden_dim)\n",
    "        self.task_heads = nn.ModuleList([nn.Linear(hidden_dim, 1) for _ in range(num_tasks)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_features = self.shared_encoder(x)\n",
    "        attended_features, attention_weights = self.attention(shared_features)\n",
    "        task_outputs = [torch.sigmoid(head(attended_features)) for head in self.task_heads]\n",
    "        return task_outputs, attention_weights\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "input_dim = prs_data.shape[1]\n",
    "hidden_dim = 128\n",
    "num_tasks = y_train.shape[1]\n",
    "\n",
    "model = MultiTaskAttentionModel(input_dim, hidden_dim, num_tasks)\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss for multi-label classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(inputs)\n",
    "            loss = sum([criterion(outputs[i].squeeze(), labels[:, i]) for i in range(num_tasks)]) / num_tasks\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs, _ = model(inputs)\n",
    "            predictions = torch.cat(outputs, dim=1)\n",
    "            all_preds.append(predictions)\n",
    "            all_labels.append(labels)\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    auc_scores = [roc_auc_score(all_labels[:, i], all_preds[:, i]) for i in range(num_tasks)]\n",
    "    average_auc = np.mean(auc_scores)\n",
    "    print(f\"Average AUC-ROC: {average_auc:.4f}\")\n",
    "    return auc_scores\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train and Evaluate\n",
    "epochs = 20\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=epochs)\n",
    "evaluate_model(model, test_loader)\n",
    "\n",
    "# Summary and Analysis\n",
    "# 1. After training, use SHAP or other interpretability tools to understand feature importance.\n",
    "# 2. Visualize the attention weights to see which features were most attended for different disease tasks.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch",
   "language": "python",
   "display_name": "Python (pyTorch)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}